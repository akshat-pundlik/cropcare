import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
import datetime

# --- CONFIGURATION (MUST BE CUSTOMIZED) ---
# ðŸš¨ 1. DATASET PATH: Change this to the main folder containing your image data.
# The script assumes this folder has subdirectories for each class.
DATA_DIR = 'path/to/your/Plant_Disease_Dataset_Folder' 

# ðŸš¨ 2. NUMBER OF CLASSES: Update this with the total count of disease/healthy classes.
NUM_CLASSES = 38  # Example: If you use the full PlantVillage dataset (38 classes)

# 3. TRAINING PARAMETERS
BATCH_SIZE = 32
IMG_HEIGHT = 128
IMG_WIDTH = 128
EPOCHS = 20
MODEL_NAME = 'trained_plant_disease_model.keras'
# ------------------------------------------


def create_data_generators(data_dir, img_height, img_width, batch_size):
    """Sets up data generators for training and validation with augmentation."""
    
    # Data Augmentation for Training: helps the model generalize
    train_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=30,
        zoom_range=0.2,
        horizontal_flip=True,
        validation_split=0.2  # Use 20% of data for validation
    )
    
    # Data Scaling for Validation (no augmentation)
    valid_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

    print("Loading Training Data...")
    train_generator = train_datagen.flow_from_directory(
        data_dir,
        target_size=(img_height, img_width),
        batch_size=batch_size,
        class_mode='categorical',
        subset='training'
    )

    print("Loading Validation Data...")
    validation_generator = valid_datagen.flow_from_directory(
        data_dir,
        target_size=(img_height, img_width),
        batch_size=batch_size,
        class_mode='categorical',
        subset='validation'
    )
    
    # Print the class names in the order Keras uses them
    print("\nDetected Class Names (in order):", train_generator.class_indices.keys())
        
    return train_generator, validation_generator


def create_model(num_classes, img_height, img_width):
    """Defines the Convolutional Neural Network (CNN) architecture."""
    
    # The architecture is based on common practice and your file's metadata
    model = Sequential([
        # Input Layer: (128, 128, 3) as per your metadata
        tf.keras.Input(shape=(img_height, img_width, 3)),
        
        # 1st Conv Block (starting with 32 filters, as suggested by your file)
        Conv2D(32, (3, 3), activation='relu', padding='same'),
        MaxPooling2D((2, 2)),
        
        # 2nd Conv Block
        Conv2D(64, (3, 3), activation='relu', padding='same'),
        MaxPooling2D((2, 2)),
        
        # 3rd Conv Block
        Conv2D(128, (3, 3), activation='relu', padding='same'),
        MaxPooling2D((2, 2)),
        
        # Classifier Layers
        Flatten(),                  
        Dropout(0.5),               # Regularization
        Dense(512, activation='relu'),
        
        # Output Layer: Softmax for multi-class classification
        Dense(num_classes, activation='softmax')
    ], name='Plant_Disease_Classifier')
    
    return model


def compile_and_train(model, train_generator, validation_generator, epochs):
    """Compiles the model and executes the training."""
    
    # --- Model Compilation ---
    model.compile(
        optimizer='adam',                               
        loss='categorical_crossentropy',                
        metrics=['accuracy']
    )

    model.summary()
    
    # --- Callbacks ---
    # Stops training early if validation loss doesn't improve
    early_stopping_callback = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss', 
        patience=5,
        restore_best_weights=True
    )
    
    # Saves the model with the best validation accuracy
    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
        filepath=MODEL_NAME,
        monitor='val_accuracy',
        mode='max',
        save_best_only=True
    )

    # --- Model Training ---
    print("\nStarting model training...")
    history = model.fit(
        train_generator,
        epochs=epochs,
        validation_data=validation_generator,
        callbacks=[model_checkpoint_callback, early_stopping_callback]
    )
    
    return history


# --- MAIN EXECUTION BLOCK ---
if __name__ == "__main__":
    
    # 1. Setup Data Generators
    train_gen, valid_gen = create_data_generators(DATA_DIR, IMG_HEIGHT, IMG_WIDTH, BATCH_SIZE)
    
    # 2. Create Model
    model = create_model(NUM_CLASSES, IMG_HEIGHT, IMG_WIDTH)
    
    # 3. Train and save the model
    compile_and_train(model, train_gen, valid_gen, EPOCHS)
    
    print(f"\nTraining complete! The best model was saved as: {MODEL_NAME}")
